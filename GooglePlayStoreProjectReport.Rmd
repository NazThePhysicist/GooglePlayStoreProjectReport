---
title: "GooglePlayStoreProjectReport"
author: "Nazanin Komeilizadeh"
date: "November 22, 2018"
output: 
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction

Kaggle has hosted a web scraped dataset of 10,000 play store apps for analyzing the Android market. The aim of this  project is to carry out extensive data exploration on this dataset to reveal insights for the Android App development sphere. Through various views of this dataset, I am attempting to reveal patterns, if any, to assist companies/individuals engaged in Android app development to focus on the most profitable strategy for app development.

I have also attempted to predict the rating of an app based on the random forest machine learning algorithm for regression.

## Data Wrangling

###	Load & Preparation

As a first step, we read in the data. The `tidyverse` package is most suitable for data wrangling operations as it contains all the requisite libraries/packages for cleaning and pre-processing data. The `lubridate` package is ideally suited for dealing with date fields. We start off by loading the requisite libraries.

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
```

We can now read in the data that was downloaded from [here](https://www.kaggle.com/lava18/google-play-store-apps).

```{r, message=FALSE, warning=FALSE}
googleplaystore <- read_csv("googleplaystore.csv")
glimpse(googleplaystore)
#View(googleplaystore)
```
The `glimpse()` function allows us to have a quick look at the data. As can be seen, the data comprises of 10,841 rows or observations and 13 columns/variables. We can see that `Size`, `Installs` and `Price` should ideally be numeric variables but have been read in as character variables. We will have to carry out some data wrangling steps to clean these variables.


Let's see how many `NA` values are there using the following. We see that `Rating` have 1474 missing values. 

```{r, message=FALSE, warning=FALSE}
colSums(is.na(googleplaystore))
```

To look for duplicate records, we can use the `distinct()` function from `dplyr` package. 
```{r, message=FALSE, warning=FALSE}
nrow(googleplaystore %>% distinct()) #There are 10358 distinct rows
```

Performing the following code, we remove the duplicated rows. We then check the structure of our data frame. 

```{r, message=FALSE, warning=FALSE}
googleplaystore <- googleplaystore[!duplicated(googleplaystore),] 
nrow(googleplaystore)
#View(googleplaystore)
str(googleplaystore)  #no duplicated anymore
```

Let's take a closer look at variables `Rating`, `Installs`, `Size` and `Price`: 

#### Rating: 

Let's look at the summary of `Rating` variable. 

```{r, message=FALSE, warning=FALSE}
summary(googleplaystore$Rating)    
plot(density(googleplaystore$Rating, na.rm = TRUE))
```

We notice that there is a data point whose Rating is 19, which is definitly an outlier. Since `Rating` is out of 5; can't be more than 5. This needs to be removed. Let's check again how many values are greater than 5?

```{r, message=FALSE, warning=FALSE}
nrow(googleplaystore %>% filter(Rating>5))  #Just one row, presumably with 19
nrow(googleplaystore$Rating >5)
```

So let's get rid of it as well as the 1465 `NA` values: 

```{r, message=FALSE, warning=FALSE}
googleplaystore <- googleplaystore %>% filter(Rating <= 5)
```

The density plot of `Rating` looks like: 

```{r, message=FALSE, warning=FALSE}
plot(density(googleplaystore$Rating)) 
```

What can you say about this distribution is that it seems that it's skewed to the right and the big portion of the `Rating` is between 4 and 5. 

#### Size:

Let's look at the summary of Size variable. 

```{r, message=FALSE, warning=FALSE}
summary(googleplaystore$Size)
``` 

We observe that there are 1468 `NA` values in the `Size` variable. We also need to do a bit of a clean-up on this column. 

##### `Size` variable Clean-up: 

The `Size` variable has the letter "M" and "k" appended with the numeric value indicating Mega bytes and kilo bytes. We will now remove these values and convert the variable to a numeric. Let's remove all the "M"'s from the `Size` column and convert "k"'s to "M"'s (in number). 

```{r, message=FALSE, warning=FALSE}
googleplaystore$Size <- gsub("M", "", googleplaystore$Size) #remove M from Size column 
``` 

Now, remove "k"'s from `Size` column and convert them to "M"" equivalent: 

```{r, message=FALSE, warning=FALSE}
googleplaystore$Size[grepl("k", googleplaystore$Size)] <- as.numeric(gsub("k","", googleplaystore$Size[grepl("k", googleplaystore$Size)]))/1024

#Dividing by 1024 and not 1000 as 1 kb = 1024 bytes
```

Let's convert the `Size` variable to numeric: 

```{r, message=FALSE, warning=FALSE}
googleplaystore$Size <- as.numeric(googleplaystore$Size)
class(googleplaystore$Size)
```

Let's plot the density for the `Size` variable. 

```{r, message=FALSE, warning=FALSE}
plot(density(googleplaystore$Size, na.rm = TRUE)) #What can we say about the size of apps?
```

The 1637 NAs are 'Varies with device'. Let's have a quick look at the summary of `Size` now.

```{r}
 summary(googleplaystore$Size)
#View(googleplaystore$Size)
#View(googleplaystore)
``` 

Now that the `Rating` and `Size` variables are cleaned up. We need to go after `Installs` and `Price`. Similarly, we can now cleanup `Installs` and `Price` variables.

#### Installs:

Let's look at the `Installs` variable to see what needs to be cleaned up. 

```{r, message=FALSE, warning=FALSE}
summary(googleplaystore$Installs)
``` 

Let's remove all the "+" and "," from the `Installs` variable. 

```{r, message=FALSE, warning=FALSE}
googleplaystore$Installs <-  gsub("[^0123456789]", "", googleplaystore$Installs)
```

Looking at the `Installs` variable class, we need to convert it into numeric. 

```{r, message=FALSE, warning=FALSE}
class(googleplaystore$Installs)

googleplaystore$Installs <- as.numeric(googleplaystore$Installs)
class(googleplaystore$Installs)
```

#### Price:

Let's take a look at `Price` variable to see what needs to be cleaned up. 

```{r, message=FALSE, warning=FALSE}
summary(googleplaystore$Price)
``` 

Let's remove the "$" from the `Price` variable. 

```{r, message=FALSE, warning=FALSE}
googleplaystore$Price <-  gsub("[^0123456789\\.]", "", googleplaystore$Price) 
```

```{r, message=FALSE, warning=FALSE}
#View(googleplaystore$Price)
```

Let's convert the `Price` variable to numeric. 
```{r, message=FALSE, warning=FALSE}
googleplaystore$Price <- as.numeric((googleplaystore$Price))
class(googleplaystore$Price)
```

Lastly, we notice that `Last Updated` is a character variable but should ideally be a date field. We can convert it by using the `mdy()` function from the `lubridate` package.

```{r}
googleplaystore$`Last Updated` <- mdy(googleplaystore$`Last Updated`)
#View(googleplaystore$`Last Updated`)
str(googleplaystore$`Last Updated`)
```

## Exploratory Data Analysis

Now that we have all cleaned up data frame, let's get a better visualization of the data and to get a better idea about the distribution of the variables with respect to each other. The aim of exploratory data analysis is to slice and dice the data to answer questions about the data graphically. Let's explore whether different variables in our data frame have any influence on each other.

Firstly, we can plot a histogram and density plot to view the `Rating` distribution.

```{r}
ggplot(googleplaystore, aes(x=Rating)) + geom_histogram(aes(y=..density..), color="red", fill = "steelblue", binwidth = 0.2, alpha = 0.2) +
  geom_density() 
```

We can see that the bulk of the `Rating` is  between 4 and 5 for most apps. 

Intuitively, the following questions come to my mind for exploring this dataset: 
What types of apps are popular? To answer this question, we can have a look at the counts of `Category` variable.
Let us see which is the most popular `Category` of apps based on the number of installs and what are the top categories. 

```{r} 
 ggplot(googleplaystore, aes(Category)) +
   geom_bar(mapping = aes(x = fct_rev(fct_infreq(Category)), fill = Category)) +
   ggtitle('Popularity of Apps by Category') + 
   theme(legend.position="none")+ 
   coord_flip()
```

From the plot, we can see that apps belonging to Family, Game followed by Tools and Productivity are by far the most popular.

The next question to ask could be whether the popular apps mostly free or paid? We can utilize the same code and add `Type` as the "fill" aesthetic to answer this question.
The majority of these apps appear to be free. Monetization presumably would be through advertisements. We can have a look at only the "paid" apps to see the popularity.

```{r}
 ggplot(googleplaystore, aes(Category, fill = Type)) +
   geom_bar(mapping = aes(x = fct_rev(fct_infreq(Category)))) +
   ggtitle('Popularity of Apps by Category') + 
      coord_flip()
```

Surprisingly, Medical and Personalization are two categories that have a sizable number of paid apps. 
We can have a look at only the "paid" apps to see the popularity.

```{r}
  googleplaystore %>% filter(Type == 'Paid') %>% ggplot(aes(Category)) +
   geom_bar(mapping = aes(x = fct_rev(fct_infreq(Category)),fill = Category)) +
   ggtitle('Popularity of Paid Apps by Category') +
     theme(legend.position="none") +
   coord_flip()
```

While Family is still the most popular category even as a paid app, we can now see that Game, Personalization and Medical are popular paid apps following the Family Category.   
Now, let's look into the broader `Type` of apps, namely the "Free" ones. 

```{r}
  googleplaystore %>% filter(Type == 'Free') %>% ggplot(aes(Category)) +
   geom_bar(mapping = aes(x = fct_rev(fct_infreq(Category)),fill = Category)) +
   ggtitle('Popularity of Free Apps by Category') +
     theme(legend.position="none") +
   coord_flip()
```
 
As we see in this broader types of apps, Family, Game, Tools and Productivity are among the most popular apps.  

Another question to ask is Which apps have the highest ratings? Since we can saw that the bulk of the ratings are between 4 and 5 for most apps, we can now set the bar for a high rate app to be rating of greater than 4.9.  

```{r} 
 googleplaystore %>% filter(Rating > 4.9 ) %>% ggplot(aes(Category)) +
   geom_bar(mapping = aes(x = fct_rev(fct_infreq(Category)), fill = Category)) +
   ggtitle('Popularity of Apps by Category with High Rating') +
   theme(legend.position="none") +
          coord_flip() 
``` 

Doing so, seems like "Family" `Category` continues to take the lead followed by "Life Style" and "Medical" and "Business". Looking more into the popularity of apps by `Category` with high `Rating`, switching the criteia of high `Rating` from 4.9 to 4.7 is interesting. 

```{r} 
 googleplaystore %>% filter(Rating > 4.7 ) %>% ggplot(aes(Category)) +
   geom_bar(mapping = aes(x = fct_rev(fct_infreq(Category)), fill = Category)) +
   ggtitle('Popularity of Apps by Category with High Rating') +
   theme(legend.position="none") +
          coord_flip() 
``` 

Looking into the is the `Size` of these highly rated apps to see the dependency of the app `Size` to `Rating`:

```{r}
 googleplaystore %>% filter(Rating > 4.9 ) %>% ggplot(aes(x = Category, y = Size, col = Rating)) +
     geom_point() +
   geom_density()+
   ggtitle('High Rating App Categories vs Size') +
   coord_flip() 
```

And switching the threshold from 4.9 to 4.7 is interesting:
 
```{r}
 googleplaystore %>% filter(Rating > 4.7 ) %>% ggplot(aes(x = Category, y = Size, col = Rating)) +
     geom_point() +
   geom_density()+
   ggtitle('High Rating App Categories vs Size') +
   coord_flip() 
```
 
## Machine Learning 
 
We have a supervised regression type problem for this dataset we have, for which we shall use `randomForest()` technique to predict the outcome variable, "Rating". We are mainly interested in dependency of `Rating` on other variables, hence, we shall predict the rating of an app based on random forest machine learning algorithm for regression.
Loading the libraries we would need along the process. 

```{r}
library(randomForest)
library(caret)
library(caTools)
library(rpart)
library(rpart.plot)
```

Prior to splitting our dataset into training and testing datasets, we need to make sure that the variables are either factors or numeric as the `randomForest()` function will try to impute for missing values, but only for factor/numeric variables. Doing so, we remove the variables we don't need in our Machine Learning process as well as we convert all the character variables to factors. 

```{r}
summary(googleplaystore)

  googleplaystore <- googleplaystore %>% select(-App, -`Last Updated`, -`Current Ver`)
  googleplaystore$Category <- as.factor(googleplaystore$Category)
  googleplaystore$Type <- as.factor(googleplaystore$Type)
  googleplaystore$`Content Rating` <- as.factor(googleplaystore$`Content Rating`)
  googleplaystore$Genres <- as.factor(googleplaystore$Genres)
  googleplaystore$`Android Ver` <- as.factor(googleplaystore$`Android Ver`)
```

On a closer look at the naming of the variables, we see that we need to remove spaces from column names as this will cause problems. 

```{r}
 colnames(googleplaystore)[8] <- "ContentRating"
 colnames(googleplaystore)[10] <- "Version"
 #View (googleplaystore)
```

Also `randomForest()` model cannot handle more than 53 categorical levels so we check the number of levels for our categorical variables. 

```{r} 
 length(levels(googleplaystore$Genres))
``` 
 
Since 115 is not acceptable for the algorithm; we'll need to do some cleaning on `Genres` variable. 
We first remove everything after the semi colon: 

```{r}  
 googleplaystore$Genres <- gsub("(.*);.*", "\\1", googleplaystore$Genres)
 googleplaystore$Genres <- as.factor(googleplaystore$Genres)
 length(levels(googleplaystore$Genres))
```

48 is handleable. We also remove "February 11, 2018".  

```{r} 
 googleplaystore <- googleplaystore %>% filter(Genres != "February 11, 2018")
``` 

Let us now split our dataset into training and testing datasets. 

```{r}
set.seed(123) # set the seed to make sure we all get the same result
  split = sample.split(googleplaystore$Rating, SplitRatio = 0.7)
  train = subset(googleplaystore, split == TRUE)
  test = subset(googleplaystore, split == FALSE)
```

Let's apply Machin Learning to the prediction of `Rating` on other factors in our dataset, in other words, `Rating` is the outcome variable. Regression trees are needed when the response variable is numeric or continuous, which is in our case for our target variable, the prediction of `Rating`. 
Now, using `rpart()` function, let's predict the dependency of the outcome variable `Rating` on other variables. 

### Prediction Model - CART Modeling via `rpart`

```{r}
googleplaystoreTree = rpart(Rating ~ . , data = train, method = "anova", control = rpart.control(minbucket = 8))
``` 
  
To visulaize the tree, let's try using the `prp` function. 

```{r}

prp(googleplaystoreTree)

```

Now let's predict on the Testing set.

```{r}  
predictCART = predict(googleplaystoreTree, newdata = test, na.action = na.pass)
```

To find out how the algorithm is performing as far as accuracy, one way is to find out the mean absolute error, MAE. For that, we need to write a function to compare the precidtions to the actual values for the target feature, `Rating`. The lower the MAE, the better the fit. 

```{r}
MAE <- function(actual, predicted){mean(abs(actual-predicted))}
MAE
MAE(test$Rating, predictCART)
```


### Prediction Model - Random Forest (Regression)

##### Advantages of Random Forest over Decision Trees

Although Random Forest method adds to the complexity of the model and makes it less interpretable, it has one big advantage over a decision tree method, and that is that it reduces overfitting and is therefore more accurate. Random Forest is capable of reducing the overfitting by averaging several trees and hence there is a lower risk of overfitting, therefore, the model has less variance. This one advantage is enough for Random Forest to be used when creating predicting models. 
Let's do `randomForest()` to see if the prediction we get from `randomForest()` is a better one. 

```{r}    
googleplaystoreForest = randomForest(Rating ~ . , data = train, nodesize = 25, ntree = 250, na.action=na.roughfix)
predictForest = predict(googleplaystoreForest, newdata = test)
```

Now, let's plot the error rate of the Random Forest model:

```{r}
plot(googleplaystoreForest)
```

Looking at the error plot of the Random Forest model, `ntree = 250` seems to be a good tuning parameter for the number of trees in the Random Forest model in our project. Moreover, as we see, the regression RF model shows a smaller error rate compared to the CART model. 

### Classification Trees 

#### Prediction Model - CART  

Let us treat this problem, this time around, as a classification problem where we are trying to classify the new outcome variable `RatingClass`. 

Classifying the `Rating` variable to different classes of "Bad", "Moderate", "Good" and "Excelent" as follows, we now predict the outcome variable `RatingClass` based on other variable in the dataset. 

```{r}
googleplaystore$RatingClass <- ifelse(googleplaystore$Rating <= 3, "Bad",
                                       ifelse(googleplaystore$Rating > 3 & googleplaystore$Rating <= 4, "Moderate",
                                              ifelse(googleplaystore$Rating >4 & googleplaystore$Rating <= 4.5, "Good", "Excellent")))
 
```

Let us see what the distribution is like as per this classification: 

```{r}
table(googleplaystore$RatingClass)
googleplaystore$RatingClass <- as.factor(googleplaystore$RatingClass)
```
 
 
#### Prediction Model  
##### SMOTE Computation -- `SmoteClassif()`
##### Random Forest 

Table of `RatingClass` in our dataset shows that the four classes have imbalanced observations.   
SMOTE (Synthetic Minority Oversampling Technique) synthesises new minority instances between existing, real, minority instances. 
Basically, SMOTE draws lines between existing minority instances and then creates new, synthetic minority instances somewhere on these lines. In other words, SMOTE is a function that oversample the rare event by using bootstraping and k-nearest neighbors and it synthetically creates more obseravtion of the rare event to the dataset. Since the response variable, `RatingClass`, is imbalanced in our dataset, we now utilize the SMOTE function that's used for imbalanced datasets to oversample the rare event for us. 
To use SMOTE class, we need to install and load the following libraries.  

```{r}
library(randomForest)
library(ggplot2)
library(UBL)
library(caret)
library(caTools)
library(rpart)
library(rpart.plot)
library(e1071)
library(ROSE)
library(DMwR)
library(grid)
library(lattice)
library(abind)
library(zoo)
library(xts)
library(quantmod)
library(ROCR)
library(bitops)
library(MBA)
library(gstat)
library(automap)   
library(sp)
```

Since the `Rating` variable got converted into `RatingClass`, we remove the `Rating` from the data set. 

```{r}
googleplaystore <- select(googleplaystore, -Rating)

#keeping only the complete cases in the data set: 

cc <- as.data.frame(googleplaystore[complete.cases(googleplaystore),])
cc <- cc %>% mutate_if(is.character, as.factor)
summary(cc) 
prop.table(table(cc$RatingClass))
newdata <- SmoteClassif(RatingClass ~., dat = cc, C.perc = 'balance', dist = "HEOM")

# checking the newdata table to see the proportion of different classes of Rating Class
prop.table(table(newdata$RatingClass)) #as we see, it's evenly distributed 
```

##### Random Forest model:

We split the data into train and test stes to prepare it for the RF machine learning process: 

```{r}
set.seed(123) # set the seed to make sure we all get the same result
split = sample.split(newdata$RatingClass, SplitRatio = 0.7)
train = subset(newdata, split == TRUE)
test = subset(newdata, split == FALSE)
```


```{r}
googleplaystoreForest2 = randomForest(RatingClass ~ . , data = train, nodesize = 25, ntree = 250, na.action = na.roughfix)

predictForest2 = predict(googleplaystoreForest2, newdata = test, type = "class")

confusionMatrix(predictForest2, test$RatingClass)
plot(googleplaystoreForest2)
legend("topright", colnames(googleplaystoreForest2$err.rate),col=1:4,cex=0.8,fill=1:6)

``` 

##  Conclusion and Outlook 

The aim of this project is to carry out extensive data exploration and machine learning on GooglePlayStore dataset to reveal insights for the Android App development sphere.

In the Exploratory Data Analysis phase of the project, we observed that the Popularity of Apps by Category is lead by Family and Game followed by Tools and Productivity. Including the types of Free and Paid apps, it shows that Medical and Personalization apps are the two categories with substantial number of paid apps, despite the fact that Family, Games and Tools are still the top three of the Paid and Free apps. Considering apps with high Rating (Rating of greater than 4.7 out of 5) Family, Medical and Lifestyle are the top three of the apps among other categories. 

Moving on to the Machin Learning phase of the project, we have a supervised regression type problem for this dataset, for which we use CART and randomForest() techniques to predict the outcome of "Rating" variable based on the other variables. Using a Prediction Model, CART Modeling via `rpart`, the mean absolute error, MAE, is 0.3508982. The Random Forest counterpart showed, `ntree = 250` to be a good tuning parameter for the number of trees in the Random Forest model. Moreover, the regression RF shows a smaller error rate compared to the CART model once the error rate was ploted. 

Utilizing Random Forest prediction model, once again with Classification trees and by classifying `Rating` variable into "Bad", "Moderate", "Good" and "Excellent" rating classes; since our `Rating` variable is not balanced in terms of the number of observations in each class, we use SMOTE (Synthetic Minority Oversampling Technique) computation via `SmoteClassif()` function. The Random Forest results from SMOTE computation shows the best prediction for predicting the "Bad" class followed by "Excellent", "Moderate" and "Good" class with an overall accuracy of 0.5929.  
Further investigations were performed by reducing the number of independed variables to `Category`, `Reviews`, `Size`, `Installs`, `ContentRating` and `Genres`, however, the overall accuracy proved to reduce to 0.5624 so no furhter improvements were shown. 



 